---
name: py2to3-bytes-string-fixer
description: |
  Highest-risk semantic skill for Python 2→3 bytes/str boundary fixing.
  Handles I/O boundaries, binary protocols (Modbus, SCADA), EBCDIC mainframe data,
  serial communications, CNC machine text, and mixed-encoding legacy systems.
  Detects and fixes bytes/str mismatches at socket recv/send, file I/O with
  binary vs. text modes, struct.pack/unpack flows, and legacy protocol handlers.
---

# Skill 3.1: Bytes/String Boundary Fixer

## Why This Is the Highest-Risk Semantic Skill

Python 2 conflates bytes and str: a byte string `b'abc'` and a unicode string `u'abc'`
were subtly different, but plain `'abc'` was bytes under Python 2 yet str under Python 3.
This ambiguity **lives at every I/O boundary**:

- **SCADA/Modbus protocols**: Read binary frames over TCP socket → must stay bytes until
  you parse fields with `struct.unpack()`. If treated as text, byte values are corrupted.
  Endianness matters. CRC calculations break if bytes are decoded prematurely.

- **Mainframe EBCDIC**: Legacy COBOL/RPG systems send EBCDIC-encoded data (e.g., `cp500`
  or `cp1047`). Hardcoded byte comparisons in Python 2 code (e.g., `b == 0xC1` to check
  for 'A' in EBCDIC) silently fail if you mix cp037 vs cp500. ASCII/UTF-8 decode will
  garble the data completely.

- **Serial port reads**: CNC machines, lab instruments, older devices send binary frames
  with packed structs, checksums, and mode bytes. Data must flow as bytes through parsing
  logic; only final display/logging should decode to str.

- **Binary file I/O**: Python 2 `open(f)` reads bytes; Python 3 `open(f)` reads str.
  Blindly changing to `open(f, 'rb')` in some paths but not others causes inconsistency.

- **Mixed encodings in one system**: Legacy data warehouses mix ASCII file exports (UTF-8
  or Latin-1) with binary packed-binary protocol frames, all flowing through one module.
  One function may need bytes, another needs str—the boundary is the critical zone.

**The cost of error**: Wrong boundary classification means:
- Silent data corruption (SCADA controllers receiving garbage commands)
- Protocol parsing failures (CRC mismatches, field offsets wrong)
- Mainframe sync issues (data can't be re-imported or audited)
- Crashes at runtime (TypeError: expected bytes, got str)

This skill **prevents silent data corruption** by classifying every bytes/str boundary,
auto-fixing clear cases, and escalating ambiguous cases to human review with full context.

---

## Inputs

| Input | From | Notes |
|-------|------|-------|
| **codebase_path** | User | Root directory of the Python 2 codebase |
| **conversion_unit_path** | User or from Phase 2 | Specific module or file to process (or entire codebase) |
| **bytes-str-boundaries.json** | Phase 0 Data Format Analyzer (0.2) | Raw bytes/str boundary detections; lists every potential mix point in AST |
| **data-layer-report.json** | Skill 0.2 | Identifies functions as binary-layer, text-layer, or mixed-layer |
| **migration-state.json** | Migration State Tracker | Tracks what's been done; updates with bytes-str decisions |
| **target_version** | User or config | Python 3.x target (e.g., 3.9, 3.11, 3.12) |
| **--state-file** | User | Path to migration-state.json for decision tracking |
| **--dry-run** | User | Show what would change without modifying files |
| **--auto-only** | User | Skip ambiguous cases; only apply high-confidence fixes |

---

## Outputs

| Output | Purpose |
|--------|---------|
| **Modified source files** | Files with fixes applied (unless --dry-run) |
| **bytes-str-fixes.json** | JSON log of every fix: location, boundary type, fix applied, rationale, confidence |
| **decisions-needed.json** | Ambiguous boundaries that need human review: data flow context, options, impact |
| **encoding-annotations.json** | Every .encode()/.decode() call: codec used, whether it's correct, risk level |
| **bytes-str-boundary-report.md** | Markdown summary for human consumption (generated by generate_boundary_report.py) |

---

## Scope and Chunking

This is the highest-context-cost skill in the suite. Bytes/string boundary analysis requires the agent to reason about data flow across function boundaries, which means it needs to hold more context per file than any other skill. Budget accordingly.

**Mandatory scoping**: Always scope to a single conversion unit. Never run this skill against the entire codebase at once.

**Within a conversion unit**:
- Process 5–10 files per invocation for modules with heavy binary I/O (protocols, serialization, encoding)
- Process 10–20 files per invocation for modules with primarily text-mode operations
- After each batch, save the `bytes-str-fixes.json` and `decisions-needed.json` outputs and update the migration state

**Prioritization within a unit**: Process files in this order:
1. I/O boundary modules (network, file, database) — these define the bytes/str contract
2. Serialization modules — these must agree with the I/O boundary decisions
3. Data processing modules — these consume the contracts established above
4. Everything else

**Human review checkpoints**: After processing the I/O boundary modules, pause and present the `decisions-needed.json` to the user. These decisions propagate to all downstream files — getting them wrong means redoing the entire unit.

**Key principle**: Quality over speed. This skill's output correctness determines whether Phase 3 succeeds or fails. Take small bites and verify as you go.

---

## Workflow

### 1. Load Phase 0 Boundary Map

The Phase 0 Data Format Analyzer produces a `bytes-str-boundaries.json` listing every AST node
where bytes and str interact. This includes:

```json
{
  "boundaries": [
    {
      "file": "scada/modbus.py",
      "line": 45,
      "type": "socket_recv",
      "source_var": "data",
      "dest_usage": "struct.unpack",
      "context": "frame_parser()",
      "confidence_bytes": 0.95,
      "confidence_text": 0.05
    },
    {
      "file": "legacy/ebcdic.py",
      "line": 12,
      "type": "open_binary",
      "source_var": "file_handle",
      "dest_usage": "string_comparison",
      "context": "read_cobol_record()",
      "confidence_bytes": 0.60,
      "confidence_text": 0.40
    }
  ]
}
```

Load this JSON as the **starting point** for all downstream analysis.

### 2. Classify Each Boundary

For every boundary in the map, determine its classification:

#### **BYTES-NATIVE** (keep as bytes)

High confidence that data should remain bytes throughout:

- **struct.pack/unpack**: Results are bytes; parsing struct fields happens on bytes.
  ```python
  # Bytes-native: struct.unpack returns bytes, don't decode until display
  frame = socket.recv(1024)  # bytes
  (msg_id, flags, length) = struct.unpack('>HBH', frame[:5])  # unpack from bytes → ints
  ```

- **socket.recv/send**: Network data is bytes. Even if it contains text, the network
  layer doesn't decode.
  ```python
  # Bytes-native
  data = socket.recv(4096)  # explicitly bytes
  socket.send(data)  # send bytes back
  ```

- **os.read / file opened in 'rb' mode**: System calls return bytes.
  ```python
  # Bytes-native
  with open(filename, 'rb') as f:
      raw_data = f.read()  # bytes
  ```

- **Serial port reads (pyserial, serial.Serial.read())**: Bytes from the wire.
  ```python
  # Bytes-native
  ser = serial.Serial('/dev/ttyUSB0', 9600)
  packet = ser.read(10)  # bytes
  ```

- **CRC/checksum calculations**: Operate on individual bytes, not characters.
  ```python
  # Bytes-native
  def crc16(data: bytes) -> int:
      for byte in data:  # iterate over ints, not chars
          ...
  ```

#### **TEXT-NATIVE** (decode to str)

High confidence that data is intended as text:

- **str.format / % formatting**: String building for output/logging.
  ```python
  # Text-native
  msg = f"Received {count} items"  # str, not bytes
  print(msg)
  ```

- **print() / logging**: Display layer always uses str.
  ```python
  # Text-native
  log.info(f"Frame ID: {frame_id}")  # str for logging
  ```

- **UI display / configuration files**: User-facing strings.
  ```python
  # Text-native
  config_value = config.get('name')  # str for display
  ```

- **JSON serialization output**: json.dumps() expects str (or objects), not bytes.
  ```python
  # Text-native
  json_str = json.dumps(data)  # str, not bytes
  ```

- **Database string columns**: ORM inserts text, not raw bytes (unless BLOB column).
  ```python
  # Text-native
  db.insert(table='users', name=user_name)  # str
  ```

#### **MIXED/AMBIGUOUS** (needs human decision)

Boundary is unclear or crosses layer boundaries in ways that need human judgment:

- **Data flows from binary source to string operation without explicit conversion**:
  ```python
  # Ambiguous: is this EBCDIC or ASCII? Is it text or a binary field?
  frame = socket.recv(512)  # bytes (binary-layer)
  # ...later...
  if frame[10:15] == 'HELLO':  # comparing bytes to str literal — will fail in Py3
      # Should this be frame[10:15] == b'HELLO'? Or decode first with known codec?
  ```

- **Legacy code with implicit type mixing**:
  ```python
  # Ambiguous: function parameter type unclear
  def process_record(data):
      # data could be bytes (from file) or str (from user input)
      # and the function doesn't document which
      return data.split(':')  # works in Py2, crashes in Py3 if bytes
  ```

- **Encoding not specified** (especially EBCDIC or non-UTF-8 legacy codecs):
  ```python
  # Ambiguous: is this cp500 (international) or cp037 (US)? Are there CRC bytes?
  data.decode()  # which codec? defaults to UTF-8 — wrong for EBCDIC!
  ```

---

### 3. Apply Automatic Fixes (High Confidence)

For boundaries classified as BYTES-NATIVE or TEXT-NATIVE with confidence ≥ 0.85:

#### **BYTES-NATIVE Fixes**

**a) Struct unpack results**
```python
# Before (buggy in Py3):
data = socket.recv(256)
(id,) = struct.unpack('>H', data[:2])
if id == 0x1234:  # ok, ints
    ...

# After (explicit, correct):
data = socket.recv(256)
assert isinstance(data, bytes), "socket.recv must return bytes"
(id,) = struct.unpack('>H', data[:2])
if id == 0x1234:
    ...
```

**b) File binary mode**
```python
# Before (ambiguous):
with open('protocol.dat') as f:
    frame = f.read(512)  # Py2: bytes; Py3: str — broken!

# After (explicit):
with open('protocol.dat', 'rb') as f:
    frame = f.read(512)  # Py3: bytes ✓
```

**c) Socket recv kept as bytes**
```python
# Before (implicit):
data = conn.recv(1024)
parsed = parse_modbus_frame(data)  # expects bytes

# After (assertion for clarity):
data = conn.recv(1024)
assert isinstance(data, bytes), "conn.recv returns bytes in Python 3"
parsed = parse_modbus_frame(data)
```

#### **TEXT-NATIVE Fixes**

**a) Decode for display**
```python
# Before (py2: str is bytes, silent):
message = socket.recv(256).decode('utf-8')
print(message)

# After (explicit codec):
message = socket.recv(256).decode('utf-8')
print(message)  # ✓ already correct in Py3
```

**b) File text mode with encoding**
```python
# Before (py2 implicit encoding):
with open('config.ini') as f:
    config = f.read()

# After (explicit, cross-platform):
with open('config.ini', encoding='utf-8') as f:
    config = f.read()
```

**c) String formatting stays str**
```python
# Before (mixing):
msg = "Got: " + data.decode('utf-8')

# After (explicit):
if isinstance(data, bytes):
    msg = "Got: " + data.decode('utf-8')
else:
    msg = "Got: " + data
```

---

### 4. Generate decisions-needed.json for Ambiguous Cases

For boundaries with confidence between 0.5–0.85 or missing context:

```json
{
  "decisions": [
    {
      "file": "legacy/ebcdic.py",
      "line": 42,
      "boundary_type": "ambiguous_comparison",
      "source_code": "if record[0:5] == 'XXXXX':",
      "context": "read_mainframe_record()",
      "data_flow": {
        "source": "file opened as binary (rb)",
        "current_operation": "string literal comparison",
        "next_use": "stored in list, used in JSON export"
      },
      "confidence_bytes": 0.50,
      "confidence_text": 0.50,
      "options": [
        {
          "option": 1,
          "description": "Keep as bytes, use b'XXXXX' comparison",
          "rationale": "Data comes from binary file; comparison is field matching in EBCDIC protocol"
        },
        {
          "option": 2,
          "description": "Decode with cp500 early, compare with 'XXXXX'",
          "rationale": "If this is text data from mainframe, EBCDIC decode is needed"
        },
        {
          "option": 3,
          "description": "Document data format in function docstring, request clarification",
          "rationale": "Function signature doesn't specify if result is bytes or str; need developer input"
        }
      ],
      "impact": "If wrong codec chosen, data will be garbled; if bytes/str mismatch, TypeError at runtime",
      "next_step": "Review with domain expert (SCADA/mainframe) to confirm data format"
    }
  ]
}
```

---

### 5. Record Encoding Annotations

Every `.encode()` and `.decode()` call in the codebase:

```json
{
  "encoding_annotations": [
    {
      "file": "scada/modbus.py",
      "line": 78,
      "operation": "decode",
      "codec": "utf-8",
      "context": "message logging",
      "confidence": 0.95,
      "risk": "low",
      "note": "Modbus text fields (device name) are documented as ASCII/UTF-8"
    },
    {
      "file": "legacy/ebcdic.py",
      "line": 23,
      "operation": "decode",
      "codec": "cp500",
      "context": "mainframe record ingestion",
      "confidence": 0.75,
      "risk": "medium",
      "note": "Codec cp500 is common but variant cp037 is possible; requires verification with IBM reference"
    },
    {
      "file": "legacy/ebcdic.py",
      "line": 101,
      "operation": "decode",
      "codec": "None (implicit UTF-8)",
      "context": "legacy field parsing",
      "confidence": 0.20,
      "risk": "high",
      "note": "Data is EBCDIC mainframe data; UTF-8 decode will produce garbage; fix immediately"
    }
  ]
}
```

---

## SCADA/Modbus Protocol Handling

Modbus and similar binary protocols require **strict bytes discipline**:

1. **Read frames as bytes** from socket/serial:
   ```python
   # TCP Modbus:
   data = socket.recv(256)  # bytes ✓
   
   # RTU (serial):
   data = ser.read(256)  # bytes ✓
   ```

2. **Parse with struct.unpack on bytes**:
   ```python
   (unit_id, func_code, byte_count) = struct.unpack('>BBB', data[:3])
   # unpack works with bytes, returns ints
   ```

3. **Validate CRC on bytes**:
   ```python
   # CRC operates on raw bytes
   crc_calc = crc16_modbus(data[:-2])  # bytes input
   crc_recv = struct.unpack('>H', data[-2:])[0]  # bytes
   assert crc_calc == crc_recv
   ```

4. **Build response frames in bytes**:
   ```python
   response = struct.pack('>BBB', unit_id, func_code, byte_count)  # bytes
   response += register_values
   response += struct.pack('>H', crc16_modbus(response))
   socket.send(response)  # bytes ✓
   ```

5. **Only decode for logging/display**:
   ```python
   log.info(f"Sent {len(response)} bytes")  # str (count)
   # Don't decode binary frames themselves
   ```

---

## EBCDIC Handling

Mainframe systems using EBCDIC require explicit codec specification at data ingestion:

1. **Identify EBCDIC data sources** (from data-layer-report.json):
   - Files marked as EBCDIC
   - Functions documented as "mainframe data handler"
   - Byte comparisons with EBCDIC-range values (0xC1–0xE9 for letters)

2. **Add explicit decode at ingestion point**:
   ```python
   # Before (Py2 implicit, wrong in Py3):
   with open('mainframe_export.dat', 'rb') as f:
       records = f.read()  # bytes
   # ...later...
   if records[0] == 'X':  # comparing bytes to str — wrong!
       
   # After (explicit cp500 decode):
   with open('mainframe_export.dat', 'rb') as f:
       records_bytes = f.read()  # keep as bytes for now
   records_text = records_bytes.decode('cp500', errors='replace')
   # Now records_text is str, safe to compare with 'X'
   ```

3. **Verify codec variant** (cp037, cp500, cp1047, cp273):
   - cp500: most common (international)
   - cp037: US/Canada
   - cp1047: Latin-1 extended
   - **Document which variant is used** in function docstring

4. **Handle mixed records**:
   ```python
   # Some fields EBCDIC, some binary (e.g., timestamps as big-endian int64)
   ebcdic_part = record[0:100].decode('cp500')  # text
   timestamp = struct.unpack('>Q', record[100:108])[0]  # binary int
   ```

---

## File I/O Handling

### Binary Files

```python
# Py2 (implicit):
with open('data.bin') as f:
    data = f.read()  # bytes in Py2

# Py3 (explicit — our fix):
with open('data.bin', 'rb') as f:
    data = f.read()  # bytes ✓
```

### Text Files

```python
# Py2 (implicit UTF-8/system default):
with open('config.txt') as f:
    lines = f.readlines()  # bytes in Py2, but often treated as str

# Py3 (explicit):
with open('config.txt', encoding='utf-8') as f:
    lines = f.readlines()  # str ✓
```

### Legacy Non-UTF-8 Codecs

```python
# Latin-1 file (e.g., Windows-1252 legacy data):
with open('legacy_export.csv', encoding='latin-1') as f:
    data = f.read()  # str, decoded with latin-1

# EBCDIC file:
with open('mainframe_data.dat', 'rb') as f:
    raw = f.read()  # bytes
data = raw.decode('cp500')  # str, EBCDIC decoded
```

---

## Integration with Migration State Tracker

Record every bytes/str decision in migration-state.json:

```json
{
  "modules": {
    "scada/modbus.py": {
      "phase": "3-semantic",
      "bytes_str_status": "in_progress",
      "decisions_made": 12,
      "decisions_pending": 3,
      "risk_level": "high",
      "notes": [
        "Modbus frames kept as bytes through parsing layer",
        "Display functions explicitly decode to str",
        "Pending: CRC function needs endianness verification"
      ]
    }
  }
}
```

---

## Model Tier

**Sonnet** (with Haiku pre-processing). The core task — deciding whether a variable holds bytes or text and choosing the correct fix — requires semantic understanding of data flow. Haiku cannot reliably make these decisions.

Decomposition: Haiku identifies all byte/str boundary locations (calls to encode/decode, socket.recv, file I/O without encoding, struct.pack). Sonnet receives only these locations with surrounding context and decides the fix strategy. This reduces Sonnet's token consumption by ~70% compared to feeding it entire files.

## References

- **encoding-patterns.md**: EBCDIC codecs, mixed encoding detection
- **bytes-str-patterns.md**: Common bytes/str anti-patterns and fixes
- **scada-protocol-patterns.md**: Modbus, CANbus, serial protocol specifics
- **serialization-migration.md**: struct.pack/unpack, pickle, protobuf in Py3

---
- `references/SUB-AGENT-GUIDE.md` — How to delegate work to sub-agents: prompt injection, context budgeting, parallel execution

## Success Criteria

- [ ] All socket recv/send operations stay as bytes
- [ ] All struct.pack/unpack operations work on bytes, results are ints/tuples
- [ ] All file I/O has explicit mode ('rb'/'r') or encoding parameter
- [ ] All .decode() calls have explicit codec (not implicit UTF-8 for EBCDIC data)
- [ ] All EBCDIC data ingestion points have cp500/cp037/cp1047 decode
- [ ] No implicit str←→bytes operations (e.g., comparing bytes to str literal)
- [ ] bytes-str-fixes.json has 100% coverage of detected boundaries
- [ ] decisions-needed.json has clear options and impact analysis for ambiguous cases
- [ ] encoding-annotations.json documents every codec used and its correctness
